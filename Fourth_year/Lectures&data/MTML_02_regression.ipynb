{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViSYw-TJZbK0"
      },
      "source": [
        "ls -lh /content/sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQfkHMu-3u55"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "quartet = pd.read_json('/content/sample_data/anscombe.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCgI_N_esC-Q"
      },
      "source": [
        "quartet.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xoCY-TiujYn"
      },
      "source": [
        "data = quartet[quartet.Series=='I'].set_index('X').sort_index()[['Y']]\n",
        "data.plot(style='+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDJPYzxeqDRP"
      },
      "source": [
        "Регре́ссия (лат. regressio — обратное движение, отход) в теории вероятностей и математической статистике — односторонняя стохастическая зависимость, устанавливающая соответствие между случайными переменными, то есть математическое выражение, отражающее связь между зависимой переменной у и независимыми переменными х при условии, что это выражение будет иметь статистическую значимость.\n",
        "\n",
        "Если мы точно знаем как устроено распределение x и y - решением задачи занимается математика. А если у нас есть только выборка?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrQIm2BoiC5u"
      },
      "source": [
        "a = 5\n",
        "def foo(x):\n",
        "  return a * np.sqrt(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-eNN8lxmC25"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xx = np.linspace(4, 14)\n",
        "plt.plot(xx, '+')\n",
        "xx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdxQpWQHo_rK"
      },
      "source": [
        "data.plot(style='+')\n",
        "plt.plot(xx, foo(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl1HJsxtniln"
      },
      "source": [
        "## Интерполяция\n",
        "В каком-то смысле задача похожая - провести линию/поверхность через точки. Заполнить пространство между ними какими-то промежуточными значениями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaHWPUkKwUGU"
      },
      "source": [
        "from scipy import interpolate\n",
        "interp = interpolate.interp1d(data.index, data.Y, kind='nearest')\n",
        "\n",
        "data.plot(style='+')\n",
        "xx = np.linspace(data.index.min(), data.index.max(), 100)\n",
        "plt.plot(xx, interp(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXyCvHs4Fs2s"
      },
      "source": [
        "data.plot(style='+')\n",
        "plt.plot(xx, interpolate.interp1d(data.index, data.Y, kind='quadratic')(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aruf8YyFF0rs"
      },
      "source": [
        "data.plot(style='+')\n",
        "plt.plot(xx, interpolate.interp1d(data.index, data.Y, kind='nearest')(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAa9VG37npfF"
      },
      "source": [
        "# Регрессии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1q3RwaypqPm"
      },
      "source": [
        "## Линейная (метод наименьших квадратов)\n",
        "\n",
        "Линейные методы предполагают, что между признаками объекта (features) и целевой переменной (target/label) существует линейная зависимость, то есть\n",
        "$$y = w_1 x_1 + w_2 x_2 + ... + w_k x_k + b, $$ где   \n",
        "$у$ --- целевая переменная (что мы хотим предсказать),   \n",
        "$x_i$ --- признак объекта $х$,   \n",
        "$w_i$ --- вес $i$-го признака,   \n",
        "$b$ --- bias (смещение, свободный член)  \n",
        "\n",
        "  \n",
        "**Функция потерь** --- это мера количества ошибок, которые наша линейная регрессия делает на наборе данных \n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "L(y_{pred}, Y) &=  \\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{pred} - Y\\right)^2 \n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEyeQJEUraK_"
      },
      "source": [
        "foo = lambda x: 2 * x/3 + 2\n",
        "data.plot(style='+')\n",
        "plt.plot(xx, foo(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KvLdb4kK8FN"
      },
      "source": [
        "X = data.index.values.reshape(-1, 1)\n",
        "xx = np.linspace(data.index.min(), data.index.max(), 100).reshape(-1, 1)\n",
        "print(X.shape, xx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgEsZmnEtVFK"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linear = LinearRegression()\n",
        "linear.fit(X, data.Y)\n",
        "print(linear.coef_, linear.intercept_)\n",
        "a = linear.coef_[0]\n",
        "b = linear.intercept_\n",
        "data.plot(style='+')\n",
        "plt.plot(xx, a * xx + b)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-TuilfQI0Ba"
      },
      "source": [
        "data.plot(style='+')\n",
        "plt.plot(xx, linear.predict(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze_mgx5TPd2h"
      },
      "source": [
        "## Полиномиальная\n",
        "\n",
        "Вместо прямых линий подбираем параболы, гиперболы и т.д.\n",
        "\n",
        "Конкретно в sklearn для этого применяют не отдельную модель, а препроцессор который добавляет степени x к набору входных параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e6CFZN7KsPq"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "x2 = poly.fit_transform(X)\n",
        "plt.plot(x2)\n",
        "x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvIOuyExMKCU"
      },
      "source": [
        "model2 = LinearRegression(fit_intercept=False).fit(x2, data.Y)\n",
        "model2.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZXnrF1L6fl"
      },
      "source": [
        "data.plot(style='+')\n",
        "xx2 = poly.transform(xx.reshape(-1, 1))\n",
        "plt.plot(xx, model2.predict(xx2))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcX4NoHZlhpY"
      },
      "source": [
        "В `Pipeline` хранятся все этапы рабочего процесса в виде единого объекта"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx3273OQNS5P"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Pipeline([('poly', PolynomialFeatures(degree=12)),\n",
        "                  ('linear', LinearRegression(fit_intercept=False))])\n",
        "\n",
        "model.fit(X, data.Y)\n",
        "data.plot(style='+')\n",
        "plt.plot(xx, model.predict(xx))\n",
        "model['linear'].coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим возможное переобучение, но компьютер не умеет смотреть на графики. Как формализовать этот вопрос?"
      ],
      "metadata": {
        "id": "1u7_RLv_iMT8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl3A3DXS4ZxX"
      },
      "source": [
        "## Валидация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd1NRBbl4v1a"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "score=[]\n",
        "X_ = data.index.values.reshape(-1, 1)\n",
        "for n in range(12):\n",
        "  model = Pipeline([('poly', PolynomialFeatures(degree=n)),\n",
        "                    ('linear', LinearRegression(fit_intercept=False))])\n",
        "  model.fit(X_, data['Y'])\n",
        "  score.append(mean_squared_error(data['Y'], model.predict(X_)))\n",
        "plt.plot(score)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H18Kx1hAWqFB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtr, Xtest, Ytr, Ytest = train_test_split(data.index.values.reshape(-1, 1), data['Y'], random_state=11)\n",
        "print([d.shape for d in (Xtr, Xtest, Ytr, Ytest)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-0jZB4rYVyM"
      },
      "source": [
        "train_score=[]\n",
        "test_score=[]\n",
        "for n in range(5):\n",
        "  model = Pipeline([('poly', PolynomialFeatures(degree=n)),\n",
        "                    ('linear', LinearRegression(fit_intercept=False))])\n",
        "  model.fit(Xtr, Ytr)\n",
        "  train_score.append(mean_squared_error(Ytr, model.predict(Xtr)))\n",
        "  test_score.append(mean_squared_error(Ytest, model.predict(Xtest)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hOodP-MXn6f"
      },
      "source": [
        "score = pd.DataFrame({'train': train_score, 'test': test_score})\n",
        "score.train.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teqLQRVoX9sM"
      },
      "source": [
        "score.test.plot()\n",
        "plt.show()\n",
        "\n",
        "score.test.plot(logy=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zlgz_lO5kdf"
      },
      "source": [
        "plt.plot(Xtr, Ytr, '+')\n",
        "plt.plot(Xtest, Ytest, '+')\n",
        "plt.plot(xx, Pipeline([('poly', PolynomialFeatures(degree=1)),\n",
        "                  ('linear', LinearRegression(fit_intercept=False))]).fit(Xtr, Ytr).predict(xx))\n",
        "plt.plot(xx, Pipeline([('poly', PolynomialFeatures(degree=4)),\n",
        "                  ('linear', LinearRegression(fit_intercept=False))]).fit(Xtr, Ytr).predict(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYzKpLfCCy5S"
      },
      "source": [
        "## Кроссвалидация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAyiV0m-pIvP"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=19TOWCsLwIjNSmcHzu46f6JqY5TEefm9h' width=600/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x2hRTVYBsuE"
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "cv = ShuffleSplit(32, test_size=2, random_state=13)\n",
        "cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mhOyNhSCKjq"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "score = pd.DataFrame(columns=['mean', 'std'])\n",
        "for n in range(14):\n",
        "  model = Pipeline([('poly', PolynomialFeatures(degree=n)),\n",
        "                    ('linear', LinearRegression(fit_intercept=False))])\n",
        "  sc = cross_val_score(model, X, data.Y, cv=cv, scoring='neg_mean_squared_error')\n",
        "  score.loc[n] = [-sc.mean(), sc.std()]\n",
        "score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18ZlSn_DjvQ"
      },
      "source": [
        "score.plot(logy=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ_uZXuOFU1q"
      },
      "source": [
        "score[:4]['mean'].plot()\n",
        "score['mean'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0xbmHS2P5q5"
      },
      "source": [
        "plt.plot(X, data.Y, '+')\n",
        "plt.plot(xx, Pipeline([('poly', PolynomialFeatures(degree=1)),\n",
        "                  ('linear', LinearRegression(fit_intercept=False))]).fit(X, data.Y).predict(xx))\n",
        "plt.plot(xx, Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
        "                  ('linear', LinearRegression(fit_intercept=False))]).fit(X, data.Y).predict(xx))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ApOoICT7HzP"
      },
      "source": [
        "## Модели с регуляризацией\n",
        "\n",
        "Борьба с переобучением со стороны уменьшения пространства поиска в окрестности небольших значений параметров модели.\n",
        "\n",
        "Суть регуляризации состоит в том, чтобы добавлять к функции потерь слагаемое, ограничивающее рост весов модели.   \n",
        "Например, обычная версия линейной регрессии выглядит так:\n",
        "$$\\frac{\\sum\\limits_{i=1}^{\\ell}\\left|\\left|\\langle x^i, w\\rangle - y^i\\right|\\right|^2}{\\ell} \\rightarrow \\min_{w}.$$\n",
        "\n",
        "Регуляризованная версия:\n",
        "$$\\frac{\\sum\\limits_{i=1}^{\\ell}\\left|\\left|\\langle x^i, w\\rangle - y^i\\right|\\right|^2}{\\ell} + \\lambda\\left|\\left|w\\right|\\right|_2^2\\rightarrow \\min_{w}.$$\n",
        "\n",
        "Такая версия линейной регресси называется **Ridge**-регрессией.  \n",
        "\n",
        "\n",
        "В **LASSO** мы штрафуем модель  **на сумму модулей всех ее весов** (на l1-норму весов), таким образом:\n",
        "\n",
        "$$\\frac{\\sum\\limits_{i=1}^{\\ell}\\left|\\left|\\langle x^i, w\\rangle - y^i\\right|\\right|^2}{\\ell} + \\lambda\\left|\\left|w\\right|\\right|_1\\rightarrow \\min_{w}.$$\n",
        "\n",
        "**ElasticNet** использует как L1, так и L2 регуляризации:\n",
        "\n",
        "$$\\frac{\\sum\\limits_{i=1}^{\\ell}\\left|\\left|\\langle x^i, w\\rangle - y^i\\right|\\right|^2}{\\ell}  + \\lambda_2\\left|\\left|w\\right|\\right|_2^2 + \\lambda_1\\left|\\left|w\\right|\\right|_1 \\rightarrow \\min_{w}.$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2EYbV95O2c2"
      },
      "source": [
        "model_poly11 = Pipeline([('poly', PolynomialFeatures(degree=11)),\n",
        "                         ('linear', LinearRegression(fit_intercept=False))])\n",
        "model_poly11.fit(X, data.Y)\n",
        "data.plot(style='+')\n",
        "plt.plot(xx, model_poly11.predict(xx))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKXrHlc74Dvw"
      },
      "source": [
        "model_poly11['linear'].coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DxEKiouVZVn"
      },
      "source": [
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "model = Pipeline([('poly', PolynomialFeatures(degree=11)),\n",
        "                  ('linear', ElasticNet())])\n",
        "model.fit(X, data.Y)\n",
        "data.plot(style='+')\n",
        "plt.plot(xx, model.predict(xx))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp59zTbH36yl"
      },
      "source": [
        "model['linear'].coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUS3X5rP6AAS"
      },
      "source": [
        "score = pd.DataFrame(columns=['mean', 'std'])\n",
        "for n in range(10):\n",
        "  model = Pipeline([('poly', PolynomialFeatures(degree=n)),\n",
        "                    ('linear', ElasticNet(fit_intercept=False, tol=1e-4, random_state=13))])\n",
        "  sc = cross_val_score(model, X, data.Y, cv=cv, scoring='neg_mean_squared_error')\n",
        "  score.loc[n] = [-sc.mean(), sc.std()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8PkFjM8GKh6"
      },
      "source": [
        "score.plot(logy=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgnhQ4i0GQf1"
      },
      "source": [
        "score[1:8]['mean'].plot()\n",
        "score['mean'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFP1ZnbycCqS"
      },
      "source": [
        "x_ = np.linspace(2, 16).reshape(-1, 1)\n",
        "\n",
        "pd.DataFrame(\n",
        "  {n: Pipeline([('poly', PolynomialFeatures(degree=n)),\n",
        "                 ('linear', ElasticNet(fit_intercept=False))]).fit(X, data.Y).predict(x_)\n",
        "                 for n in (2, 6)},\n",
        "  index = x_[:,0]\n",
        ").plot()\n",
        "plt.plot(X, data.Y, '+')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_cSY68QilH5"
      },
      "source": [
        "## Логистическая "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bDx1K8VqfqX"
      },
      "source": [
        "Вместо вещественных чисел будем предсказывать числа из [0, 1]\n",
        "\n",
        "Получается что мы решаем другую задачу и пришли к теме следующего семинара (классификация).\n",
        "\n",
        "\n",
        "<img src='https://miro.medium.com/max/640/0*gKOV65tvGfY8SMem.png' width=600/>\n",
        "\n",
        "$\\displaystyle\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n",
        "\n",
        "Задача теперь формулируется так:\n",
        "\n",
        "**Предсказания:** $$\n",
        "y_{pred}(x, w) = \\frac{1}{1 + e^{-\\langle x, w \\rangle}}\n",
        "$$\n",
        "\n",
        "**Функция потерь (LogLoss):** $$\n",
        "L(y_{pred}, y) = -y\\, log\\,y_{pred} - (1-y)\\,log\\,(1-y_{pred})\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4W2kdLcikOn"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "yhat = [x*0.01 for x in range(0, 101)]\n",
        "losses_0 = [log_loss([0], [x], labels=[0,1]) for x in yhat]\n",
        "losses_1 = [log_loss([1], [x], labels=[0,1]) for x in yhat]\n",
        "plt.plot(yhat, losses_0, label='y=0')\n",
        "plt.plot(yhat, losses_1, label='y=1')\n",
        "plt.ylim((0, 5))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4hswkxwwA5y"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X, y = make_blobs(n_samples=1000, centers=[[-2,0.5],[2,-0.5]], cluster_std=1, random_state=13)\n",
        "\n",
        "colors = (\"red\", \"k\")\n",
        "colored_y = np.zeros(y.size, dtype=str)\n",
        "\n",
        "for i, cl in enumerate([0,1]):\n",
        "    colored_y[y == cl] = str(colors[i])\n",
        "    \n",
        "plt.figure(figsize=(15,10))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=colored_y, edgecolors='K', s=80)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKZ2Jbka6MZf"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(x=y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPmlpVr5wA3P"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(random_state=0)\n",
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoe2hEyWwA00"
      },
      "source": [
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "eps = 0.1\n",
        "xx, yy = np.meshgrid(np.linspace(np.min(X[:,0]) - eps, np.max(X[:,0]) + eps, 500),\n",
        "                     np.linspace(np.min(X[:,1]) - eps, np.max(X[:,1]) + eps, 500))\n",
        "\n",
        "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "cmap_light = ListedColormap(['#FFAAAA', 'grey'])\n",
        "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=colored_y, edgecolors='K')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoAEoBGyyhZu"
      },
      "source": [
        "# Задание\n",
        "\n",
        "1. Попытаться применить линейную регрессию к какой-либо паре зависимой и независимой переменных в собственном наборе данных. Нарисовать график зависимости y от x с линией. Кроссвалидацией оценить ошибку (любая метрика ошибки на ваш выбор).\n",
        "2. Теперь при той же зависимой переменной y взять в качестве независимых переменных все (числовые) переменные набора данных. График нарисовать уже не получится, но кроссвалидацией всё равно можно оценить ошибку с той же выборкой. Стала ли ошибка меньше за счет того, что у модели больше информации?\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}